\chapter{The \texttt{afl} Approach}

% TODO: mention somewhere afl is targetted mainly for binary inputs

At a high level, \texttt{afl} has only a two goals: given some input corpus,
as quickly and reliably as possible:

\begin{enumerate}
    \item Create test cases that reach new program states
    \item Identify inputs that cause the process to die due to some
    OS signal (e.g. \texttt{SIGSEV} or \texttt{SIGABRT})
\end{enumerate}

That's it -- \texttt{afl} just repeatedly mutates input files in order to
``evolve'' more interesting test cases out of thin air.
\texttt{afl}'s novelty compared to other fuzzing tools comes from its
efficiency and core feedback loop: special instructions are inserted into the
target binary at compile-time, and during program execution every branch
statement reports back to the controlling process whenever it is executed.
Thus, \texttt{afl} can efficiently classify newly-mutated test cases based on
the number and diversity of branch statements they cause to be executed.

Test cases that cause a program to crash or hang are archived along with
execution metadata.

\section{Core Operations}

% TODO
% mention some stuff about the overall layout so the rest of this makes
% sense. in particular, there is a controlling process that spins up
% other child processes.

% mention that program gets run with a special wrapper, afl-fuzz

% in-depth overview


\subsection{Classifying Program State}

\texttt{afl} classifies program state by labeling branch statements
as a $(src, dst)$ 2-tuple and maintaining a global map of
$(src, dst) \rightarrow hitcount$. A handle to the global map is passed
to the target binary, and every time a branch statement is hit the map
gets updated.

A program state is considered ``new'', and the corresponding test case
worth saving, if either of the following two conditions are met:
\begin{itemize}
    \item A new (not seen in previous executions) $(src, dst)$ tuple is produced
    \item A new tuple hit count is produced
\end{itemize}

Hit counts are approximate and grouped into the following buckets\cite{afl-whitepaper}: $\{1\}, \{2\}, \{3\}, \{4-7\}, \{8-15\}, \{16-31\}, \{32-127\}, \{128+\}$. A new hit count only counts toward a new state if the branch tuple
hit count changes buckets.

\subsection{Compile-time Instrumentation}

\texttt{afl} injects code at \textit{every} branch point in the target
binary to capture both overall branch coverage and a rough measure of branch 
hit counts for every program execution.
Figure \ref{fig:injection} shows the simplified version of the code
injected around branch statements\cite{afl-whitepaper}. \\

\begin{figure}[H]
    \begin{lstlisting}[language={[ANSI]C}]
cur_location = <COMPILE-TIME RANDOM>;
shared_mem[cur_location ^ prev_location]++;
prev_location = cur_location >> 1;
\end{lstlisting}
\caption{Simplified version of the code injected around branch statements}
\label{fig:injection}
\end{figure}

In Line 1, \texttt{cur\_location} is a randomly-generated identifier
assigned to each branch statement. In Line 2, the global branch tuple hit count
is updated for the corresponding $(src, dst)$ tuple. The right shift in Line 3
preserves directionality of tuples and ensures the following two
qualities: if $A$ and $B$ are two branch identifiers, $(A, B) \neq (B, A)$ and
$(A, A) \neq (B, B)$.

\subsection{Exploring New Program States}

% TODO: when to save a test case

\section{Fuzzing Strategies}

% TODO: set this up?

\subsection{Test Case Evolution}

% TODO: mention how test cases are evolved

\subsection{Deterministic Fuzzing Methods}

\texttt{afl} uses a combination of deterministic and random fuzzing strategies.
The fuzzing techniques are performed in sequence, with each stage
creating new test cases that are used as input for the next stage. Exactly
when the fuzzer transitions from one stage to the next is determined by an
algorithm that weighs expected new state coverage against the performance
loss by continuing the current stage. Overview of \texttt{afl} fuzzing
stages comes from \cite{afl-fuzzing-blogpost}.

\subsubsection{Walking Bit Flips}

The first mutation strategy \texttt{afl} uses is simple bit flips. The bit
flips are done sequentially, with a single step, across the entire file.

\subsubsection{Walking Byte Flips}

The next step is walking byte flips: 8-, 16-, and 32-byte bitflips performed
sequentially across the input file.

\subsubsection{Arithmetic}

\texttt{afl} then tries to perform simple arithmetic operations
on all integers in the input file: the fuzzer tries both addition and
subtraction of random bytes\footnote{\texttt{afl} restricts the arithmetic range to $[-35, 35]$\cite{afl-whitepaper}} for each
individual byte, 16-byte value, and 32-byte value\footnote{\texttt{afl} tries 16- and 32-byte arithmetic operations in both endians, providing the operation would have affected the significant byte(s)\cite{afl-whitepaper}}.

\subsubsection{Known Integers}

The final deterministic fuzzing stage uses a strategy \texttt{afl} refers
to as \textit{known integers}: manually chosen integers likely to cause
edge cases or errors (e.g. $-1, 256, MAX\_INT$, etc.) are substituted
in for integer values in the program.

\subsection{Random Fuzzing}

\subsubsection{Stacked Tweaks}

The first randomized strategy \texttt{afl} uses, \texttt{stacked tweaks},
consists of a sequential loop through the following randomized operations
over test cases in the input queue:

\begin{enumerate}
	\item Bit flips
	\item Attempts to set human-chosen ``interesting'' values
    \item Simple additiona and subtraction
    \item Completely random byte-set substitutions
    \item Block deletion
    \item Block duplication or insertion
    \item Block memset
\end{enumerate}

The stack of operations is looped over as the file is repeatedly mutated.

\subsubsection{Test Case Splicing}

The final fuzzing strategy employed simply randomly pairs test cases from
the input queue, randomly chooses a point near the middle of both files,
and splices them together to create a new test input.

\section{Optimizations}
% TODO: set this up => smart optimization means more states explored

\subsection{Pruning the Input Queue}

% TODO

\subsection{Trimming Test Cases}

% TODO

\subsection{Copy-on-write Process Clones}

% TODO
