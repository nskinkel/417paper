\chapter{The \texttt{afl} Approach}

At a high level, \texttt{afl} has only a two goals: given some binary\footnote{While optimized for binary inputs, \texttt{afl} can also handle more verbose, human-readable input formats (e.g. SQL, XML). However, these techniques are less advanced, less efficient, less commonly used, and considered out of scope for this report.}
input corpus, as quickly and reliably as possible:

\begin{enumerate}
    \item Create test cases that reach new program states
    \item Identify inputs that cause the process to die due to some
    OS signal (e.g. \texttt{SIGSEV} or \texttt{SIGABRT})
\end{enumerate}

That's it -- \texttt{afl} just repeatedly mutates input files in order to
``evolve'' more interesting test cases out of thin air.
\texttt{afl}'s novelty compared to other fuzzing tools comes from its
efficiency and core feedback loop: special instructions are inserted into the
target binary at compile-time, and during program execution every branch
statement reports back to the controlling process whenever it is executed.
Thus, \texttt{afl} can efficiently classify newly-mutated test cases based on
the number and diversity of branch statements they cause to be executed.

Test cases that cause a program to crash or hang are archived along with
execution metadata.

\section{Core Operations}

Programs to be fuzzed with \texttt{afl} are built using special compiler
wrappers (\texttt{afl-gcc}, \texttt{afl-g++}, \texttt{afl-clang}, or
\texttt{afl-clang++}, as appropriate). The main fuzzer, \texttt{afl-fuzz},
is then run on the output binary and acts as a monitor and controlling
process, communicating with the target binaries through instructions
inserted by the compiler wrappers.

\texttt{afl} maintains a queue of test cases that it loops over while
executing various fuzzing strategies. This input queue is initially seeded
with test files from the user, and as the fuzzing proceeds the queue is
augmented with new test cases produced through the mutation process.

\subsection{Classifying Program State}

\texttt{afl} classifies program state by labeling branch statements
as a $(src, dst)$ 2-tuple and maintaining a global map of
$(src, dst) \rightarrow hitcount$. A handle to the global map is passed
to the target binary, and every time a branch statement is hit the map
gets updated.

A program state is considered ``new'', and the corresponding test case
worth saving, if either of the following two conditions are met:
\begin{itemize}
    \item A new (not seen in previous executions) $(src, dst)$ tuple is produced
    \item A new tuple hit count is produced
\end{itemize}

Hit counts are approximate and grouped into the following buckets\cite{afl-whitepaper}: $\{1\}, \{2\}, \{3\}, \{4-7\}, \{8-15\}, \{16-31\}, \{32-127\}, \{128+\}$. A new hit count only counts toward a new state if the branch tuple
hit count changes buckets.

When a new program state is observed, the execution's test case is placed
on the input queue for further processing\footnote{Subject to optimizations mentioned in Section \ref{sec:optimizations}.}

\subsection{Compile-time Instrumentation}

The \texttt{afl} compiler wrappers inject code at \textit{every} branch point
in the target
binary to capture both overall branch coverage and a rough measure of branch 
hit counts for every program execution.
Figure \ref{fig:injection} shows the simplified version of the code
injected around branch statements\cite{afl-whitepaper}. \\

\begin{figure}[H]
    \begin{lstlisting}[language={[ANSI]C}]
cur_location = <COMPILE-TIME RANDOM>;
shared_mem[cur_location ^ prev_location]++;
prev_location = cur_location >> 1;
\end{lstlisting}
\caption{Simplified version of the code injected around branch statements}
\label{fig:injection}
\end{figure}

In Line 1, \texttt{cur\_location} is a randomly-generated identifier
assigned to each branch statement. In Line 2, the global branch tuple hit count
is updated for the corresponding $(src, dst)$ tuple. The right shift in Line 3
preserves directionality of tuples and ensures the following two
qualities: if $A$ and $B$ are two branch identifiers, $(A, B) \neq (B, A)$ and
$(A, A) \neq (B, B)$.

\subsection{Exploring New Program States}

Test cases that reach new program states are added back to \texttt{afl}'s
input queue. This basic feedback loop allows \texttt{afl} to easily identify
test cases that produce the most reachable, unique program states and,
eventually, explore myriad program state transitions and executions through
a continually-improving iterative process, even when given a minimal input
corpus.

\texttt{afl} saves test cases only when they cause a \textit{unique} crash,
where a test case is considered unique if either of the following
conditions are met\cite{afl-whitepaper}:
\begin{itemize}
    \item The crash trace includes a $(src, dst)$ tuple not seen in any
    other crash traces.
    \item The crash trace is \textit{missing} a $(src, dst)$ tuple that was
    present in \textit{all} earlier crashes.
\end{itemize}

\subsubsection{Test Case Evolution}

By adding new and interesting mutated test cases back into the global input
queue, \texttt{afl} is able to \textit{evolve} progressively better and better
(in terms of reachable states and number of unique crashes) test cases
over time from the initial seed inputs. These evolved test cases can then be
used to manually explore program behavior and augment existing unit and
regression tests.

\section{Fuzzing Strategies}

\texttt{afl} uses a combination of deterministic and random fuzzing strategies.
The fuzzing techniques are performed in sequence, with each stage
creating new test cases that are used as input for the next stage. Exactly
when the fuzzer transitions from one stage to the next is determined by an
algorithm that weighs expected new state coverage against the performance
loss by continuing the current stage. Overview of \texttt{afl} fuzzing
stages comes from \cite{afl-fuzzing-blogpost}.

\subsection{Deterministic Fuzzing Methods}


\texttt{afl}'s deterministic fuzzing methods are the both the ``dumbest''
and most computationally efficient methods used. They are
generally able to hit many of the ``shallow'', or easy-to-reach, program states,
and output from these stages is used as input to the more advanced, randomized
fuzzing strategies.

\subsubsection{Walking Bit Flips}

The first deterministic mutation strategy \texttt{afl} uses is simple bit
flips. The bit flips are done sequentially, using a single step process across 
the entire test case.

\subsubsection{Walking Byte Flips}

The next step is walking byte flips: 8-, 16-, and 32-byte bitflips performed
sequentially across the input file.

\subsubsection{Arithmetic}

\texttt{afl} then tries to perform simple arithmetic operations
on all integers in the input file: the fuzzer tries both addition and
subtraction of random bytes\footnote{\texttt{afl} restricts the arithmetic range to $[-35, 35]$\cite{afl-whitepaper}} for each
individual byte, 16-byte value, and 32-byte value\footnote{\texttt{afl} tries 16- and 32-byte arithmetic operations in both endians, providing the operation would have affected the significant byte(s)\cite{afl-whitepaper}}.

\subsubsection{Known Integers}

The final deterministic fuzzing stage uses a strategy \texttt{afl} refers
to as \textit{known integers}: manually chosen integers likely to cause
edge cases or errors (e.g. $-1, 256, \texttt{MAX\_INT}$, etc.) are substituted
in for integer values in the program.

\subsection{Random Fuzzing}

\texttt{afl}'s randomized fuzzing modes are more computationally expensive
and time-consuming, but the tradeoff is they can often reach states that
are very difficult to reach through simple, deterministic methods.

\subsubsection{Stacked Tweaks}

The first randomized strategy \texttt{afl} uses, \texttt{stacked tweaks},
consists of a sequential loop through the following randomized operations
over test cases in the input queue:

\begin{enumerate}
	\item Bit flips
	\item Attempts to set human-chosen ``interesting'' values
    \item Simple additiona and subtraction
    \item Completely random byte-set substitutions
    \item Block deletion
    \item Block duplication or insertion
    \item Block memset
\end{enumerate}

The stack of operations is looped over as the file is repeatedly mutated.

\subsubsection{Test Case Splicing}

The final fuzzing strategy employed simply randomly pairs test cases from
the input queue, randomly chooses a point near the middle of both files,
and splices them together to create a new test input.

\section{Optimizations}
\label{sec:optimizations}

Part of \texttt{afl}'s governing design philosophy is that efficiency
leads directly to higher program state coverage and more uniquely discovered
crashes. To speed up the fuzzing process and reach the greatest number
of states per fuzzing run, \texttt{afl} employs 3 major optimization
strategies\cite{afl-whitepaper}.

\subsection{Pruning the Input Queue}

Since \texttt{afl}'s fuzzing strategies are run on each test case in the
input queue, reducing the total queue size while still reaching the same
number of program states lets \texttt{afl} do less work to get the same
overall results. Eventually, some test cases in the input queue may
provide a strict superset of program state coverage compared to earlier
test cases, and \texttt{afl} exploits this to perform its first core
optimization: pruning the input queue.

\texttt{afl} periodically scans the input queue and scores each test case
based on both its execution trace (number of unique $(src, dst)$ tuples and
their associated hit counts) and file size. The best-scoring test for
each $(src, dst)$ tuple survives until the next round, and other test
cases are pruned\footnote{\texttt{afl} is actually a bit more clever than this: low-scoring test cases are not \textit{necessarily} pruned immediately, but the full pruning algorithm is out of scope for this paper.}.

\subsection{Trimming Test Cases}

Smaller test files generally mean less work for \texttt{afl}, so \texttt{afl}
periodically attempts to reduce the size of test cases in the input queue.
Blocks are successively removed from each test file, and, if the deletion
has no effect on the execution trace (that is, the same tuples are reached
and the hit count buckets remain the same), the block deletion is finalized.

\subsection{Copy-on-write Process Clones}

The final core optimization \texttt{afl} makes is an attempt to reduce the
overhead from calling \texttt{execve()} once per test run. \texttt{afl}
inserts some \textit{additional} instructions at compile-time that let processes
\textit{wait} at a particular point in program execution
(generally, right before the first branch statement) until it receives
a \textit{go} instruction from the \texttt{afl} controlling process.

The lets \texttt{afl} spin up a master single process, take a snapshot of the
waiting process right before the first branch, and then use this snapshot to
execute many child processes. The child processes use a copy-on-write strategy 
to only update their own process image when a state change occurs.
